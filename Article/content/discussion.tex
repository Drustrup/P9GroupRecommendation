\section{Discussion} \label{sec:discussion}

Across all the methods tested we saw a similar fall in nDCG scores and distance for the distance measures as group size increased, except for some methods in Rating nDCG.

We also saw a trend of the nDCG score being a good indicator for how well the same  methods performed for the distance measure. Though SF performs well in SFD, but it falls behind on other measures, with the same to be said for Avg and its performance for Rating nDCG. This stresses the importance of testing a general purpose method from many angles.

Across all the measurements, \MC is almost identical in performance to that of BC. As the underlying heuristic of the \MC method is the Copeland Method, it raises the possibility that other extensions of Markov Chain can achieve even greater results.

However for \MC, other factors such as complexity and speed limits the utility of it compared to BC, as BC is both simple to implement and can be implemented in linear time whereas \MC is usually slower and our implementation reflected this. However optimizations for \MC and its variants exists which run in quadratic time which is a significant running time improvement\cite{rank:aggregation}.

Of all the measures, Avg has the worst results overall, depending on how Rating nDCG is viewed. The results from Rating nDCG in isolation sees Avg perform the best. So if Rating nDCG is a better measurement because it does not consider the rankings, and instead looks directly at the ratings given by the users, then Avg is providing the better recommendations. However, in such a scenario, the difference between Avg and its nearest competitor is so small that there is little practical value to gain. Should it be the case that Rating nDCG is the best measure, we have a theory about rearranging the users top-k list and order them according to average. We will expand on this in future work in Section \ref{sec:futurework}.

%All methods saw similar decreases in effectiveness across group sizes.

%BC performed best for nDCG. Other benefits include fast computation time, simple to implement. Outperforms or stands equal to various extensions we've developed. Compared with MC for nDCG, the mean difference is small, but consistent.

%MC performed 2nd best for nDCG. Our implementation is very slow, but it can be optimized a lot (probably still not faster than BC). No indication in data, but might surprise for bigger topK lists, which in turn raises the connectivity (main strength). Runs on the Copeland method, which is ill regarded for aggregation, but works reasonably well here.

%Avg generally performs poorly. It gets some good results in Adjusted nDCG, but that is a measurement uniquely advantageous for it among the methods, so it makes little sense as a measure.

%X method is the best

%When to use kendall and nDCG? For our results, it's not that important.