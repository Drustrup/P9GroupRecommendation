\subsubsection{Distance Measures}\label{sec:distance}
Before going through the distance measures, we want to cover some general notations that both methods use. $\tau(i)$ is the notation for the position of element $i$ in $\tau$. $Z = \tau_1 \cap \tau_2$, $z=|Z|$, $S$ is the set of items in $\tau_1$ but not $\tau_2$ and $T$ is vice versa, and $k$ is the length of the top-k lists.

\adparagraph{Kendall Tau Distance}
The idea of Kendall tau distance(KTD) is to compare two ranked lists based on the order in which the items appear. This basically means that it makes pairwise comparisons of item indexes $\{i,j\}$ where $i < j$, so that if $i$ is before $j$ in $\tau_1$ then this should also be the case in $\tau_2$ in order to get a good score. The score is based on a count of how many times $i$ and $j$ are in reverse order. The equation for KTD for complete lists can be seen in Equation \ref{eq:kendalldistancefinal} where $K_1$ and $K_2$ can be seen in Equation \ref{eq:kendalldistance1} and \ref{eq:kendalldistance2} respectively.

\begin{equation}\label{eq:kendalldistance1}
K_1(\tau_1,\tau_2) = | \{(i,j) | i < j, \tau_1 (i) < \tau_1 (j) \land \tau_2 (i) > \tau_2 (j)\}|
\end{equation}
\begin{equation}\label{eq:kendalldistance2}
K_2(\tau_1,\tau_2) = | \{(i,j) | i < j, \tau_1 (i) > \tau_1 (j) \land \tau_2 (i) < \tau_2 (j) \} |
\end{equation}
\begin{equation}\label{eq:kendalldistancefinal}
K(\tau_1,\tau_2) = K_1(\tau_1,\tau_2) + K_2(\tau_1,\tau_2)
\end{equation}

In order to adjust KTD for partial lists we used the $K_{Haus}$ algorithm proposed by Fagin et al\cite{comparing:topk}. This approach has four different cases.

The first case is when both $i$ and $j$ appear in $\tau_1$ and $\tau_2$. In this case the method utilizes Equation \ref{eq:kendalldistancefinal} but only on the items in the set, $Z$.

The second case is when $i$ and $j$ both appear in $\tau_1$ or $\tau_2$ but only $i$ or $j$ appears in the other. The number of cases this apply can be calculated according to Equation \ref{eq:case2}. The equation sums the position in $\tau_1$ and $\tau_2$ for the items in the sets $S$ and $T$ and subtracts it from $|\tau_1 \cup \tau_2| + 1$ which is time with $|S|$.

\begin{equation}\label{eq:case2}
(k-z)(k+z+1)- \sum_{i \in S} \tau_1(i)- \sum_{i \in T} \tau_2(i)
\end{equation}

Third case is when $i$ appears in one list and $j$ in the other. For these cases the distance is measured as $(k-z)^2$, which is the disjunctive union of both lists to the power of 2.

The fourth case is when both $i$ and $j$ appear in one list but not the other. In this case Equation \ref{eq:case4} is used. $p$ in this case is a penalty value between 0 and 1. As the method we use is an average approach this value is naturally 0.5. $p$ is multiplied with the binomial coefficient of the length of different items in the top-k lists.

\begin{equation}\label{eq:case4}
2p\left(\!
    \begin{array}{c}
      k-z \\
      2
    \end{array}
  \!\right)
\end{equation}


Combining these cases into one method, we get the $K_{Haus}$ algorithm which can be seen in Equation \ref{eq:khaus}. 
\footnotesize
\begin{equation}\label{eq:khaus}
K_{Haus}(\tau_1,\tau_2) = \frac{1}{2}(k-z)(5k-z+1)+ \sum_{i,j \in Z} K_{i,j}(\tau_1,\tau_2) + \sum_{i \in S}\tau_1(i) - \sum_{i \in S}\tau_1(i)
\end{equation}
\normalsize

The result of the $K_{Haus}$ is normalized by dividing it by $n(n-n)/2$, which gives an approximation of the average distance between the lists. It is an approximation because in case four, the method assumes that there is an equally large chance of the items being in the correct order. Due to this, the method returns 0.78 if the lists are completely disjoint. If the lists are reverse of each other it scores 1 and 0 if the lists are equal. %For a more detail explanation of $K_{Haus}$ go to Fagin et al\cite{comparing:topk} article.


\adparagraph{Spearman's Footrule Distance}
Another distance measure we use is the Spearman's Footrule Distance(SFD). SFD finds the exact distance between item $i$ in two different ranked lists containing $i$. The way it finds this item distance is by subtracting the item indexes from each other as can be seen in \ref{eq:sfd}. 

\begin{equation}\label{eq:sfd}
F(\tau_1, \tau_2) = \sum_{i=1}^{k} | \tau_1 (i) - \tau_2 (i) |
\end{equation}

As we work with partial lists we use an alternate version called $F_{Haus}$, see Equation \ref{eq:fhaus}, proposed by Fagin et al\citep{comparing:topk}.
As the lists $\tau_1$ and $\tau_2$ can contain different items, the missing index values for items are replaced by $\ell$ which is some value larger than $k$, as it follows that they would be outside the top-k list. Based on the article by Fargin et al we set $\ell$ to be equal to $(3 * k - z + 1)/2$.

\footnotesize
\begin{equation}\label{eq:fhaus}
F_{Haus}(\tau_1,\tau_2)= (k-z)(3k-z+1)+\sum_{i\in Z} | \tau_1 (i) - \tau_2 (i) | - \sum_{i\in S} \tau_1 (i) - \sum_{i\in Z} \tau_2(i)
\end{equation}
\normalsize
% some items will be missing on the lists. In order to handle this we insert $\ell$ which is equal to $(3 * k - z + 1)/2$ placing the item \note{find reason}.  

In order to normalize we divide the result of Equation \ref{eq:fhaus} by $n^2 /2$ which is the maximum value of the algorithm. Doing so we get a value of 0 if $\tau_1$ and $\tau_2$ are in the same order or 1 if the lists are the reverse of each other or completely disjoint.