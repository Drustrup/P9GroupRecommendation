\subsection{Markov Chain}\label{sec:markovchain}

%Context - Markov Chain

%Context - Dwork
Dwork et al presented 4 Markov Chain methods. The fourth method, $MC_{4}$ had the most promising results, so it is the method we use for this paper\cite{rank:aggregation}.\note{Inside or outside?}

%Technical description - Dwork
The state space corresponds to a set of all the items. The corresponding transition matrix for $MC_4$ will have an equal chance of transitioning to any other state that can beat it in a majority of pairwise contests. This approach is a generalization of the Copeland Method, where a winner is the candidate which wins the most pairwise contests, henceforth referred to as the Copeland winner.

The concept behind building the list of recommendations works by explicitly finding the transition matrix. For $MC_4$, the states are connected to other states that wins per the Copeland method. Then we can iterate through the set, and note who performs best to make the transition matrix. Using the power set on the transition matrix we can find the stationary probability distribution to aggregate the candidates.

%Technical Description - Our case
The method presented by Dwork et al is used on full lists, whereas we work on partial lists in our domain. To better suit our domain, we present some adjustments to the method. A partial list might not contain both items needed for a pairwise comparison, so in the event of only one item being on the list, it wins that pairwise contest, as the losing item must be further down the list.

For partial lists, the Copeland winner is inferred by using the available comparisons, because it is unknown whether each voter has ranked it lowly or is simply unaware of it.

For our case, we can assume that the item in a comparison not on the top-k list is lower ranked and not unknown to the voter. Any missing ratings were found by using SVD++\note{Check last report and make citation} to generate the rankings.
\note{We might need to switch this out or move it to appendix, as we "should" use the strict markov, as we for a vote probably won't have the full list for every voter but only the top-k list?}

%Strict markov chain
%For completeness, we also tested a stricter interpretation of $MC_4$ where only the majority winners with both items present were considered.
%\cite{dwork2001rank}