\section{Conclusion and Future Work}\label{sec:conclusion}
Throughout this paper we have strived to find the best performing method for aggregating individual top-k lists into one ranked list of size $k$, suitable for a group of people.

%Overall BC performer best with MC as close second. 
What we found was that BC, in most cases, proved to be the superior approach and the cases where it was outperformed, the difference was nearly insignificant. Worth noting is that MC's performance is almost as good as that of BC and further work could be done in trying to improve on these methods.

%Interesting that BC performer better than MC and SF in group recommender when it is not the case in IR
It was interesting that BC was the best performing because in a paper aggregating ranked search engine results it showed that BC was the worst, compared to SF and MF, and MF was the best performing\citep{rank:aggregation}. 

%What measures to use and in what cases to use them?
Furthermore, we want to emphasize the importance of doing extensive testing because in a more limited test run we could have concluded that Avg or SF would have been the best methods. Specifically, in the case with SF and SFD we can see how important the selection of an appropriate measure is.

That being said all the evaluation measures shows that as the group size increased the decrease in score for the measures starts to fade out. The biggest drop was between group size 4 and 8. After that the decrease fades and for most cases the decrease was less than $1\%$ between size 16 and 20.

\input{content/futurework/futurework}
