\section{Problem Areas} \label{sec:problemareas}

Within the group recommendation field, there are a few areas where there will typically be problems. Some of the problems carry over from recommender systems for individuals, for instance the cold-start problem and the popularity bias. Others are more specific to group recommending, for instance how to replicate group decision making and the satisfaction, while one is caused by the need for automatic verification of the recommending results.

\subsection{Cold-Start}
The cold-start problem is well known within the field of recommender systems, and it is also present in group recommendation\cite{recsyshandbookagreggation}. Cold-start refers to the issue that a new user in most cases does not have enough data for a recommendation to be based upon. In group recommenders the problem can be said to be less prevalent as a new user joining a group can, from the systems perspective, act as a passive member of the group until enough data has been gathered. However, there will still be problems when a large number of users in a group are new, as then the system does not work for them. It is a common problem and solutions to it that are applicable to recommender systems in general will likely be usable in group recommendation as well.

\subsection{Popularity Bias}
A common problem found in many recommender systems is the bias towards popular items\cite{popbias}. Whether this is a problem or not depends on the goal of the recommender, for instance if the goal is to recommend music new to an individual, it might not be the best choice to recommend tracks from the current top 100 hit-list as they have likely already heard them. A common goal for a recommender system is to present items to the user that they might not have known about or thought of on their own, with the same items having a high probability of being liked by the user. In group recommendation the goal is not necessarily to find new items, but rather to find something the group as a whole can be satisfied with. We will follow this belief and disregard the popularity bias.

\subsection{Group Decisions and Satisfaction}
How to properly replicate group decision making is a widely discussed topic within the group recommendation field. This is because the common method of using different aggregation strategies does not always give the best group satisfaction\cite{aggregationnotenough}. To combat this, new approaches to simulate the decision making are being continuously developed, along with research into how satisfaction of a group should be measured. It is important to note that the satisfaction of a group does not necessarily reflect the sum of satisfaction of the individual members, as for instance one member might not want to hear specific music on their own but when with a certain group, they might be okay with hearing it anyways. As an example John might not be rating country music highly but when he is with his girlfriend Jane, he listens to it because he knows it satisfies Jane.

%\subsection{Automatic Verification}
%When developing a recommender system it is important to validate the results. Herein automation is a highly sought after feature, both to speed up the process and ensure uniformity. In recommender systems for individuals there are methods available, for instance k-fold testing, however such methods requires training data that includes the satisfaction scores for the individual choices. Such training data does not exist for group recommendation, as the satisfaction for the individual choices depends on the group composition, and to the best of our knowledge such data has not been gathered in large quantity as of yet.