\subsection{Matrix Factorization} \label{bg:matrixfactorization}
%Function
Matrix Factorization(MF) is an dimensionality reduction technique in recommendation that finds latent features for items, and the propensity for users towards each latent feature. 
%Decomposing the rating matrix/Latent Semantic Indexing
%Approximating a matrix of ratings
Matrix Factorization allows for an approximation of a matrix of ratings.
%Users, u x Items, i, matrix R of rank n, approximated to two matrices of P, of size u x k, and Q, of size i x k, with k < n.
%k is the dimensional latent space.
%Performance
%Faster than both. Scales better.
Since MF approximates matrices, it scales better compared to contemporary Collective Filtering techniques and SVD, and is faster. It performs well even when data sparsity is a concern due to the matrix approximation and the dimensionality reduction.
%"for x<0.5 SVD-based prediction is
%better than the CF-Predict predictions. For x>0.5,
%however, the CF-Predict predictions are slightly
%better. This suggests that nearest-neighbor based
%collaborative filtering algorithms are susceptible to
%data sparsity as the neighborhood formation process
%is hindered by the lack of enough training data. On
%the other hand, SVD based prediction algorithms can
%overcome the sparsity problem by utilizing the latent
%relationships. However, as the training data is
%increased both SVD and CF-Predict prediction
%quality improve but the improvement in case of CFPredict
%surpasses the SVD improvement"
As data sparsity grows in a set, the more accurate every method gets, however MF has better accuracy when more than half the data is unknown, but with more than half the data known, SVD performs better.
%Performance vs other techniques (pearson and cosine, describe other techniques)
%Scales better than nearest neighbor since our matrices are approximated (smaller)
%As noted in the 2011 SysRec book - neighborhood methods have 2 flaws: Limited coverage, Sensitivity to sparse data. MF counteracts this via approximation and dimensionality reduction.
%Cosine Similarity > Pearson Correlation (Collaborative Filtering Recommender Systems by Michael D. Ekstrand)
%Reduced coverage makes pearson/cosine nearest neighbor weak (source 2000)
\subsubsection{Collective Matrix Factorization}
%Problem/specialcase introducing necessity of extension
As an extension to the MF method, Collective Matrix Factorization adds on more matrices.
%"Collective matrix factorization is a very general technique
%for revealing low-rank representations for arbitrary
%matrix collections. However, the practical applicability
%of earlier solutions has been limited since
%they implicitly assume all factors to be relevant for all
%matrices" (https://arxiv.org/pdf/1312.5921v2.pdf)
%Function
%MF is single-view
%Multi-view are many matrices
%Augmented Multi-view is CMF
%Performance vs normal MF
%???