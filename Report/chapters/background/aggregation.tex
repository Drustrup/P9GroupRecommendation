\section{Aggregation} \label{bg:aggregation} \todo{Update the this introduction to the section to reflect actual use}
When working with a group recommender system, it is hard to avoid using aggregation to make group-like decisions. While recent research has shown that current aggregation methods are not a substitute for group based decisions\cite{aggregationnotenough}, it is not our goal to find a suitable substitution for aggregation. We will instead use existing aggregation strategies to find suitable recommendations for the group. While specific strategies are as numerous as the number of recommenders, they are derived from only a few common strategies. Most of these strategies will here be presented using the ratings in Table \ref{aggregation:tbl:table_of_ratings}, while the full overview of the results of aggregation can be seen in Table \ref{aggregation:tbl:examples_of_strategies}.

The ref for intro for chapter\cite{recsyshandbookagreggation}.

\begin{table}[H]
	\centering
	\begin{tabular}{ | p{2cm} | p{1cm} | p{1cm} | p{1cm} | p{1cm} | p{1cm} | p{1cm} | p{1cm} | } \hline
		 & \textbf{A} & \textbf{B} & \textbf{E} & \textbf{D} & \textbf{E} & \textbf{F} & \textbf{G}  \\ \hline
		John & 9 & 4 & 7 & 10 & 5 & 1 & 2 \\ \hline
		Jane & 10 & 10 & 5 & 1 & 8 & 7 & 4 \\ \hline
		Bob & 1 & 8 & 4 & 4 & 6 & 10 & 6 \\ \hline
		Hilda & 1 & 7 & 2 & 9 & 5 & 10 & 3 \\ \hline
	\end{tabular}
	\caption{Arbitrary examples of ratings given by four people. The ratings were chosen to showcase the differences in the aggregation strategies.}
	\label{aggregation:tbl:table_of_ratings}
\end{table}

\textbf{Plurality Voting} attempts to gain satisfaction by selecting the items with the highest ratings for the majority of the group first, and then repeating this strategy removing any items already selected. Outlier cases can result in a minority of highly dissatisfied users, simply because their ratings are insignificant. For instance item A being rather highly scored despite two people hating it.\\

\textbf{Average} is one of the simplest ways of aggregating, by simply taking the average of the ratings for an item. As with any averaging, this is not necessarily the best approach as low ratings can be overshadowed by a significantly higher amount of high ratings. This is for instance the case with item F, where the low rating from John is overlooked in favor of the other people's ratings.\\

\textbf{Multiplicative} attempts to improve satisfaction by multiplying each rating for an item with each other, so outlier ratings at either end of the rating scale becomes more significant. This is especially true for the lowest rating, commonly adjusted to be 1, as the rating adds nothing to combined rating. Thereby items receiving the lowest rating by even a small amount of group members quickly fall towards the bottom of the recommendation. For instance this is seen in item D, where Jane's low rating drags the overall score down.\\

\textbf{Approval Voting} transforms the ratings into points for each item. The points are awarded for each group member who have a rating for the item above a certain threshold. In small groups the strategy leads to many ties, in larger groups these ties become more uncommon. In the example item E is approved by every member, and with the threshold set at 5 this is an indication that no member would be dissatisfied with this item.\\

\textbf{Least Misery} attempts to reduce the amount of misery felt by the group by using the lowest rating for an item. This leaves the items to be easily be sorted by how well they are liked by the person who likes them the least. However it also has outlier cases with items well liked by the vast majority but disliked by a single person leaving it with a low rating. This is clearly seen in item F, where John's low rating makes the item seem irrelevant despite it being highly regarded by the other three.\\

\textbf{Most Pleasure} attempts to maximize the satisfaction of the group by only using the highest rating for an item. Like the Least Misery strategy, this suffers from outlier cases going in the other direction, a single person rating an item disliked by the vast majority leaves the item with a high rating. This can be seen in item A, where it ends up with a tie for best choice, despite being hated by half the group members.\\

\textbf{Average Without Misery} works on the concept of removing as much misery as possible, this strategy removes items who have any ratings below a certain threshold, before averaging the ratings of the remaining items. However Average Without Misery suffers from outlier cases just as much as Least Misery and Most Pleasure. The example showcases another problem, where even if one person has given a rating below the threshold, then the item is completely disregarded, therefore this strategy is unsuitable at even small group sizes. In the example only two out of seven items are left for consideration.\\

\textbf{Fairness} goes by the principle of everyone-gets-a-choice, is the essence of Fairness. The items are selected in turn by each group member, and in the purest form the selection is based purely on that member's terms without regarding ratings from others. However ratings from other group members are typically used in case the selecting member has a tie between two or more items. In the example the pure form is used and notable items include item E, which has fairly high ratings from everyone but not the highest rating from anyone, leaving it to be selected second to last.\\

\textbf{Dictatorship} is also called Most Respected Decides. Letting one person and their ratings decide everything is an approach often used in real world scenarios, for instance music being decided by a dj or the movie to watch being decided by the host. However deciding which person to use as the “dictator” is typically handled using trust or respect, hence the alternative name for the strategy. Trust is difficult to measure, especially the more randomly put together the group is.

\begin{table}[H]
	\centering
	\begin{tabular}{ | p{2.5cm} | p{1cm} | p{1cm} | p{1cm} | p{1cm} | p{1cm} | p{1cm} | p{1cm} | } \hline
		& \textbf{A} & \textbf{B} & \textbf{E} & \textbf{D} & \textbf{E} & \textbf{F} & \textbf{G}  \\ \hline
		Plurality Voting & 5 & 4 & 2 & 6 & 3 & 7 & 1 \\ \hline
		Average & 5.25 & 7.25 & 4.5 & 6 & 6 & 7 & 3.75 \\ \hline
		Multiplicative & 90 & 2240 & 280 & 360 & 1200 & 700 & 144 \\ \hline
		Approval Voting (Threshold 5) & 2 & 3 & 2 & 2 & 4 & 3 & 1 \\ \hline
		Least Misery & 1 & 4 & 2 & 1 & 5 & 1 & 2 \\ \hline
		Most Pleasure & 10 & 10 & 7 & 10 & 8 & 10 & 6 \\ \hline
		Average Without Misery (Threshold 4) & - & 7.25 & - & - & 6 & - & - \\ \hline
		Fairness (Start at John) & 6 & 4 & 3 & 7 & 2 & 5 & 1 \\ \hline
		Dictatorship (Hilda) & 1 & 7 & 2 & 9 & 5 & 10 & 3 \\ \hline
	\end{tabular}
	\caption{Examples of the scores that results from applying the individual aggregation strategies to the ratings from Table \ref{aggregation:tbl:table_of_ratings}. All values have been adjusted so the highest value is the 'best'.}
	\label{aggregation:tbl:examples_of_strategies}
\end{table}

\subsection{Simulating Group Behavior} \label{bg:aggregation:groupbehavior}
In the study conducted by Judith Masthoff\todo{Ref on this and rewrite subsection}, it was found that some of the aggregation strategies were used when a group made decisions on which items to recommend, while other strategies provided better recommendations according to the groups. The strategies groups seemed to make use of were, Average, Average Without Misery, and Least Misery. In contrast to this strategies such as Multiplicative, Average, and Most Pleasure gave reasonable recommendations, showing some mismatch between what the group would recommend themselves, and what they retroactively think is best.

However these strategies were looked at independently. By combining different strategies, not only does it reduce or remove some of the downsides to using a specific strategy, it can also improve the recommendations and the satisfaction they lead to.

\subsection{Rank Aggregation}
Another aspect of aggregation is rank aggregation, where the input are lists of preferences. The goal as with any aggregation is then to find the best ordering possible. The best ordering is also known as the Kemeny Optimal\cite{DBLP:conf/www/DworkKNS01}.
Rank aggregation has to the best of our knowledge settled on two main methods, Borda and Footrule, both of which are good approximations of Kemeny optimal aggregation.\\

\textbf{Borda} or Borda Count\cite{baltrunas}\cite{borda}, works by assigning a score for each member to each item based on the item's placement on the members ordered list. Then the total score for an item is the sum of scores it got from each user. Often the individual scores are inversely proportional to the placement, so on a top $n$ list item 1 would get a score of $n$, item 2 a score of $n-1$ etc..\\

Performing Borda of two given ranked lists $L_{1} = {a,b,c,d,e}$ and $L_{2} = {c,a,f,e,d}$ would work as follows. Assign scores to each item in each list $S_{1} = {a = 5, b = 4, c = 3, d = 2, e = 1}$ and $S_{2} = {c = 5, a = 4, f = 3, e = 2, d = 1}$. Then sum up the scores for each item: $a = 9, b = 4, c = 8, d = 3, e = 3, f = 3$. According to Borda the best ordering would then be ${a, c, b, def}$, where $d, e,$ and $f$ are interchangeable.\\

\textbf{Footrule} or Spearman’s Footrule\cite{baltrunas}, is an aggregation method where the average Spearman footrule distance is minimized on the input rankings.
Between two lists, the Spearman footrule distance is the sum of absolute difference of the rank positions of each item between the two lists. If an item is present in one list of top $n$ items but not in another, the item is placed in the list it is missing from at rank $n + 1$.
For instance take the two ranked lists $L_{1}$ and $L_{2}$ from earlier. First $L_{1}$ is designated as what is called the pattern-vector which has coordinates based on the ranking in the list, e.g. a = 1, b = 2, etc.. As the item $f$ is present in $L_{2}$ but is missing in $L_{1}$ it is added as f = 6. Subsequently item $b$ is also added to $L_{2}$. This results in $L_{1}$ being the pattern-vector $(1,2,3,4,5,6)$ while $L_{2}$ becomes the vector $(3,1,6,5,4,2)$. The footrule distance between these are now easily calculated as follows $|3-1| + |1-2| + |6-3| + |5-4| + |4-5| + |2-6| = 12$.

Finding the aggregation then becomes a task of finding the minimum cost maximum matching in a bipartite graph. This should be the complete weighted bipartite graph $(C, P, W)$, where $C$ is the first set of nodes, the items being ranked; $P$ is the second set of nodes, the positions to be filled; and $W$ is the weight given by the scaled footrule distance between item $c$ and position $p$ on the form seen in Equation \ref{scaledfootruledist}, where $\tau_{i}$ are the ranked lists.

\begin{equation} \label{scaledfootruledist}
	W(c,p) = \sum_{i=1}^{k} \left | \frac{\tau_{i}(c)}{\left |\tau_{i}  \right |} - \frac{p}{n} \right |
\end{equation}

\subsection{Selecting the Comparison Base}
As we are developing new aggregation methods in an attempt to increase the group’s satisfaction with the recommended items, at least one existing aggregation should be used for the comparison. We have chosen to use both Average and Borda Count for this purpose. Average was chosen because it is the commonly used comparison, while Borda Count while being simple still manages to deliver satisfaction close to that of the more complex Spearman’s Footrule\cite{baltrunas}.